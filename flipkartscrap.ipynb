{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzRa7OQdWi8-",
        "outputId": "a289483b-224d-475e-d06f-9d41d511490e"
      },
      "outputs": [],
      "source": [
        "!pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P9FQsCqe-hu",
        "outputId": "a38d9ecf-2415-424c-cc19-1258cfbff23d"
      },
      "outputs": [],
      "source": [
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2HnOnU1fRJN",
        "outputId": "fa25d612-ca54-4e87-8363-295e75a83469"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "\n",
        "# Selenium setup\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "# Data lists\n",
        "product = []\n",
        "price = []\n",
        "brands = []\n",
        "images = []\n",
        "productlink = []\n",
        "\n",
        "# Function to process a single page\n",
        "def process_page(page_no):\n",
        "    url = f\"https://www.flipkart.com/clothing-and-accessories/ethnic-wear/kurtas/women-kurtas-and-kurtis/pr?sid=clo%2Ccfv%2Ccib%2Crkt&q=kurtas+kurtis&otracker=categorytree&otracker=nmenu_sub_Women_0_Kurtas+%26+Kurtis&fm=neo%2Fmerchandising&iid=M_737202f5-e74d-4785-9ee1-6b05e929bad3_1_372UD5BXDFYS_MC.0VYNO3UZWA0J&otracker=hp_rich_navigation_3_1.navigationCard.RICH_NAVIGATION_Fashion%7EWomen%2BEthnic%7EWomen%2BKurtas%2B%2526%2BKurtis_0VYNO3UZWA0J&otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_3_L2_view-all&cid=0VYNO3UZWA0J&page={page_no}\"\n",
        "    driver.get(url)\n",
        "    time.sleep(5)\n",
        "\n",
        "    html = driver.page_source\n",
        "    soup = BeautifulSoup(html, 'lxml')\n",
        "\n",
        "    entries = soup.find_all('div', '_1sdMkc LFEi7Z')\n",
        "    if entries:\n",
        "        for entry in entries:\n",
        "            # Getting the product name\n",
        "            try:\n",
        "                pr = entry.find(\"a\", attrs={\"class\": \"WKTcLC\"}).get(\"title\")\n",
        "                product.append(pr)\n",
        "            except Exception as e:\n",
        "                product.append(None)\n",
        "\n",
        "            # Getting the price\n",
        "            try:\n",
        "                pri = entry.find(\"div\", attrs={\"class\": \"Nx9bqj\"}).text\n",
        "                price.append(pri)\n",
        "            except Exception as e:\n",
        "                price.append(None)\n",
        "\n",
        "            # Getting the image\n",
        "            try:\n",
        "                img = entry.find(\"img\", attrs={\"class\": \"_53J4C-\"}).get(\"src\")\n",
        "                images.append(img)\n",
        "            except Exception as e:\n",
        "                images.append(None)\n",
        "\n",
        "            # Getting the product link\n",
        "            try:\n",
        "                link = entry.find(\"a\", attrs={\"class\": \"rPDeLR\"}).get(\"href\")\n",
        "                productlink.append(\"https://www.flipkart.com\" + link)\n",
        "            except Exception as e:\n",
        "                productlink.append(None)\n",
        "\n",
        "            # Getting the brand\n",
        "            try:\n",
        "                br = entry.find(\"div\", attrs={\"class\": \"syl9yP\"}).text\n",
        "                brands.append(br)\n",
        "            except Exception as e:\n",
        "                brands.append(None)\n",
        "    else:\n",
        "        print(\"No entries found with the specified class on page\", page_no)\n",
        "        print(\"Here's some of the page content to help you debug:\")\n",
        "        print(soup.prettify()[:100])\n",
        "\n",
        "for page_no in range(1, 26):\n",
        "    process_page(page_no)\n",
        "\n",
        "# Close the Selenium driver\n",
        "driver.quit()\n",
        "\n",
        "# Creating DataFrame and saving to CSV\n",
        "df = pd.DataFrame({'Image': images, 'Brand': brands, 'Name': product, 'Price': price, 'Productlink':productlink})\n",
        "print(df)\n",
        "df.to_csv('flipkart_kurtas.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rMQ8PLQs1Xc",
        "outputId": "6deaaacd-3b9d-4d7e-912a-e4c02aac1d69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(productlink)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-3QJO_j9Cgk"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"flipkart_kurtas.csv\")\n",
        "productlink=list(df[\"Productlink\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bkadGkH8G5U",
        "outputId": "6c05c62a-7f22-4e77-e58f-c4d9388d876a"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Selenium setup\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "rating = []\n",
        "sizechart = []\n",
        "\n",
        "def process_product_link(link, i):\n",
        "    try:\n",
        "        driver.get(link)\n",
        "        time.sleep(5)\n",
        "\n",
        "        html = driver.page_source\n",
        "        soup = BeautifulSoup(html, 'lxml')\n",
        "\n",
        "        # Getting the rating\n",
        "        try:\n",
        "            rate = soup.find(\"div\", class_=\"XQDdHH _1Quie7\").text\n",
        "            rating.append(rate)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to get rating for {i}: {e}\")\n",
        "            rating.append(None)\n",
        "\n",
        "        # Getting the size chart\n",
        "        try:\n",
        "            size_chart = soup.find(\"img\", class_=\"CDkImq\").get(\"src\")\n",
        "            sizechart.append(size_chart)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to get size chart for {i}: {e}\")\n",
        "            sizechart.append(None)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process link for {i}: {e}\")\n",
        "        rating.append(None)\n",
        "        sizechart.append(None)\n",
        "\n",
        "\n",
        "for i, link in enumerate(productlink):\n",
        "    process_product_link(link, i)\n",
        "\n",
        "# Close the Selenium driver\n",
        "driver.quit()\n",
        "\n",
        "\n",
        "# Creating DataFrame and saving to CSV\n",
        "df1 = pd.DataFrame({'Rating': rating, 'Size Chart': sizechart})\n",
        "print(df1)\n",
        "df1.to_csv('flipkart_kurtas1.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS8pyTzNKEGO",
        "outputId": "f206d69a-1de6-4d2e-e4e3-25831621e462"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Selenium setup\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "sizechart = []\n",
        "\n",
        "def process_product_link(link, i):\n",
        "    try:\n",
        "        driver.get(link)\n",
        "        time.sleep(5)  \n",
        "\n",
        "        WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.XQDdHH._1Quie7\")))\n",
        "\n",
        "        size_chart_link = driver.find_element(By.CSS_SELECTOR, \"div.mNjYnk\")\n",
        "        size_chart_link.click()\n",
        "\n",
        "        WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.hRtgfi\")))\n",
        "\n",
        "        size_chart_html = driver.find_element(By.CSS_SELECTOR, \"div.hRtgfi\").get_attribute(\"outerHTML\")\n",
        "\n",
        "        \n",
        "        soup = BeautifulSoup(size_chart_html, 'html.parser')\n",
        "        table = soup.find('table')\n",
        "\n",
        "        if table:\n",
        "            # Extracting table rows\n",
        "            rows = table.find_all('tr')\n",
        "            size_chart_data = []\n",
        "\n",
        "            for row in rows:\n",
        "                columns = row.find_all('td')\n",
        "                row_data = [column.get_text(strip=True) for column in columns]\n",
        "                size_chart_data.append(row_data)\n",
        "\n",
        "            sizechart.append(size_chart_data)\n",
        "        else:\n",
        "            print(f\"No size chart table found for {i}\")\n",
        "            sizechart.append(None)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to get size chart for {i}\")\n",
        "        sizechart.append(None)\n",
        "\n",
        "for i, link in enumerate(productlink):\n",
        "    if link:\n",
        "        process_product_link(link, i)\n",
        "    else:\n",
        "        sizechart.append(None)\n",
        "\n",
        "# Close the Selenium driver\n",
        "driver.quit()\n",
        "\n",
        "# Creating DataFrame and saving to CSV\n",
        "df3 = pd.DataFrame({'Size Chart': sizechart})\n",
        "print(df3)\n",
        "df3.to_csv('flipkart_kurtas1.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
